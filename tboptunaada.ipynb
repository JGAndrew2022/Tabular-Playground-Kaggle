{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-28T05:25:02.847284Z","iopub.execute_input":"2022-01-28T05:25:02.847584Z","iopub.status.idle":"2022-01-28T05:25:02.852236Z","shell.execute_reply.started":"2022-01-28T05:25:02.847553Z","shell.execute_reply":"2022-01-28T05:25:02.851152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport dateutil.easter as easter\n\ntrain = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\ngdp_df = pd.read_csv('../input/consumer-price-index-20152019-nordic-countries/Best_CPI.csv')\n\n# Nearly all of our data is categorical, and we do not know a clear correlation between categories and num_sold, so we will hot encode using scikit-learn's OneHotEnocder\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\ndef dataProcess(x):\n    one_hot = ce.OneHotEncoder(cols = ['country'])\n    x = one_hot.fit_transform(x)\n\n    one_hot1 = ce.OneHotEncoder(cols = ['store']) # Creating a new hot encoder for each column may not be the most efficient, feel free to optimize this\n    x = one_hot1.fit_transform(x)\n\n    one_hot2 = ce.OneHotEncoder(cols = ['product'])\n    x = one_hot2.fit_transform(x)\n    return x\n    \n\ndef dateProcess1(df, gdp_df):\n    # Make a bunch of columns for the dates\n    day_mon_list = []\n    mon_list = []\n    year_list = []\n\n    for k in range(len(df['date'])):\n        splt = df.iloc[k]['date'].split('-')\n        day_mon_list.append(int(splt[2]))\n        mon_list.append(int(splt[1]))\n        year_list.append(int(splt[0]) - 2015)\n    \n\n    df['day_of_month'] = day_mon_list\n    df['month'] = mon_list\n    df['year'] = year_list\n\n    gdp_list = []\n    for i in range(len(df['year'])):\n        if(df.iloc[i]['country'] == 'Finland'):\n            gdp_list.append(gdp_df.iloc[(3*df.iloc[i]['year'])]['GDP'])\n        elif(df.iloc[i]['country'] == 'Norway'):\n            gdp_list.append(gdp_df.iloc[(3*df.iloc[i]['year']) + 1]['GDP'])\n        elif(df.iloc[i]['country'] == 'Sweden'):\n            gdp_list.append(gdp_df.iloc[(3*df.iloc[i]['year']) + 2]['GDP'])\n    df['gdp_list'] = gdp_list\n\n    df['date'] = pd.to_datetime(df['date'])\n    df['weekend'] = df.date.dt.weekday >= 5 # Saturday and Sunday\n    df['friday'] = df.date.dt.weekday == 4 # Friday\n    df['day_of_year'] = df.date.dt.dayofyear\n    \n    # Christmas\n    xmas_date = df.date.dt.year.apply(lambda year: pd.Timestamp(str(year)+'-12-25'))\n    df['xmas_adjust'] = (df.date - xmas_date).dt.days.clip(lower=-20,upper=16).astype(str)\n          \n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    df['easter_adj']= (df.date - easter_date).dt.days.clip(lower =-3,upper = 60).astype(float)\n    df.loc[df['easter_adj'].isin(range(12, 39)), 'easter_adj'] = 12 \n    \n    # Black Friday\n    black_fri_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-27')),\n                                         2016: pd.Timestamp(('2016-11-25')),\n                                         2017: pd.Timestamp(('2017-11-24')),\n                                         2018: pd.Timestamp(('2018-11-23')),\n                                         2019: pd.Timestamp(('2019-11-29'))})\n    df['days_from_black_friday'] = (df.date - black_fri_date).dt.days.clip(-5, 5)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    df['days_from_wed_jun'] = (df.date - wed_june_date).dt.days.clip(-5, 5)\n    \n    #First Sunday of November (second Sunday is Father's Day)\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    df['days_from_sun_nov'] = (df.date - sun_nov_date).dt.days.clip(-1, 9)\n    \n    print(df['date'])\n    df.drop(columns=['date'],inplace=True)\n\n    \ndateProcess1(train, gdp_df)\ndateProcess1(test, gdp_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T05:25:02.85963Z","iopub.execute_input":"2022-01-28T05:25:02.860313Z","iopub.status.idle":"2022-01-28T05:25:23.420292Z","shell.execute_reply.started":"2022-01-28T05:25:02.860233Z","shell.execute_reply":"2022-01-28T05:25:23.419331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfeatures = ['country', 'store', 'product', 'day_of_month', 'month', 'year', 'day_of_year', 'weekend', 'friday', 'xmas_adjust', 'easter_adj', 'days_from_black_friday', 'days_from_wed_jun', 'days_from_sun_nov', 'gdp_list']\nlabels = ['num_sold']\nx_train = train[features]\ny_train = train[labels]\ny_train = np.ravel(y_train) # Scikit-learn didn't like my y-column unless I used this .ravel() method from numpy\nx_test = test[features]\n\n\nx_train = dataProcess(x_train)\nx_test = dataProcess(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T05:25:23.421834Z","iopub.execute_input":"2022-01-28T05:25:23.42205Z","iopub.status.idle":"2022-01-28T05:25:23.649189Z","shell.execute_reply.started":"2022-01-28T05:25:23.422023Z","shell.execute_reply":"2022-01-28T05:25:23.648511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train_train, x_train_test, y_train_train, y_train_test = train_test_split(x_train, y_train, test_size=0.3) # split the data so we can get an idea of our model's performance","metadata":{"execution":{"iopub.status.busy":"2022-01-28T05:25:23.650245Z","iopub.execute_input":"2022-01-28T05:25:23.650585Z","iopub.status.idle":"2022-01-28T05:25:23.719799Z","shell.execute_reply.started":"2022-01-28T05:25:23.650557Z","shell.execute_reply":"2022-01-28T05:25:23.71914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor","metadata":{"execution":{"iopub.status.busy":"2022-01-28T05:25:23.72111Z","iopub.execute_input":"2022-01-28T05:25:23.721758Z","iopub.status.idle":"2022-01-28T05:25:23.9376Z","shell.execute_reply.started":"2022-01-28T05:25:23.721717Z","shell.execute_reply":"2022-01-28T05:25:23.936577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the way that the competition will grade our predictions\ndef SMAPE(y_true, y_pred):\n    diff = np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200\n    return diff.mean()\n\nimport optuna\n\n\ndef objective(trial):\n    \n    rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10, 5000)\n    rf_learning_rate = trial.suggest_float(\"rf_learning_rate\", 0.001, 1.0)\n    \n    \n    classifier_obj = AdaBoostRegressor(n_estimators=rf_n_estimators, learning_rate=rf_learning_rate)\n\n    # Step 3: Scoring method:\n    classifier_obj.fit(x_train_train, y_train_train)\n    y_pred = classifier_obj.predict(x_train_test)\n    for z in range(len(y_pred)):\n        y_pred[z] = round(float(y_pred[z]))\n    smape_train = SMAPE(y_train_test, y_pred)\n    return smape_train\n\n# Step 4: Running it\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=100)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T05:25:23.93973Z","iopub.execute_input":"2022-01-28T05:25:23.940141Z","iopub.status.idle":"2022-01-28T06:06:59.830989Z","shell.execute_reply.started":"2022-01-28T05:25:23.940094Z","shell.execute_reply":"2022-01-28T06:06:59.82965Z"},"trusted":true},"execution_count":null,"outputs":[]}]}